words = ["lion", "tiger", "leopard", "banana", "strawberry", "truck", "car", "bus"]

# Change the embedding model
word_vectors = [model_glove_twitter[word] for word in words]

# Reduce dimensions with PCA
pca = PCA(n_components=2)
word_vectors_2d = pca.fit_transform(word_vectors)

plt.scatter(word_vectors_2d[:, 0], word_vectors_2d[:, 1])
for word, (x, y) in zip(words, word_vectors_2d):
    plt.annotate(word, (x, y))
plt.title("GloVe Twitter Word Embeddings (2D PCA)")
plt.show()
